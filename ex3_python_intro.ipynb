{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philberns/FTRN65/blob/main/ex3_python_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYwSTRvj5qt2"
      },
      "source": [
        "# Python environment\n",
        "We will provide exercises and handins in the form of jupyter notebooks, and suggest using one of two ways of running them.\n",
        "* Anaconda - https://docs.anaconda.com/anaconda/install/\n",
        "    * Many useful modules included by default\n",
        "    * More can be installed with `conda install <package>` or `pip install <package>`\n",
        "    * Run on your own computer or a server you control\n",
        "    * Requires installation\n",
        "* Google colab - https://colab.research.google.com/\n",
        "    * Many useful modules included by default\n",
        "    * More can be installed with `!pip install <package>` in a notebook cell\n",
        "    * Requires google account (can use the student.lu.se account you have)\n",
        "    * Revision history\n",
        "    * Just open and go, can load files from google drive, github or local computer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYQfBbFSlLVg"
      },
      "source": [
        "# Python Intro\n",
        "\n",
        "We will assume that everyone taking this course has some previous programming experience and either has experience with Python or can pick it up quickly enough. If you feel a need to brush up on your Python skills there are plenty of resources online for this, for example the [Python wiki](https://wiki.python.org/moin/BeginnersGuide/Programmers) has a page with Python tutorials for people with previous programming experience.\n",
        "\n",
        "We will try to focus more on introducing you to some of the packages commonly used for machine learning, and in this notebook we provide all the code needed to run the examples but we encourage you to make changes and make sure you understand the basic functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozfNWeQmi85Y"
      },
      "source": [
        "## PyPlot\n",
        "The module `matplotlib.pyplot` has origins in emulating MATLAB commands but is its own thing and can also be used in a pythonic object oriented way. A simple tutorial can be found [here](https://matplotlib.org/tutorials/introductory/pyplot.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSDzYFXTizV7"
      },
      "source": [
        "## Numpy\n",
        "Numpy offers high performant vectorization and numerical computation tools for the Python language. It is used in the background by many libraries but you can also use it for matrix manipulation yourself.\n",
        "\n",
        "Here we will define some data and do linear regresison in numpy. We will also set up polynomial features using numpy to get a felling for how the matrices are actually built in the background in libraries such as scikit learn where there are modules for automating this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxHoRGxdohGM"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.10' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reshape the array so that dimension 2 has size 1 and dimension 1 has the size needed for this to work\n",
        "X_train = np.linspace(0, 5, 15).reshape(-1, 1)\n",
        "y_train = np.sqrt(X_train) + 0.1 * np.random.randn(*X_train.shape)\n",
        "\n",
        "X_true = np.linspace(0, 5, 100).reshape(-1, 1)\n",
        "y_true = np.sqrt(X_true)\n",
        "\n",
        "plt.scatter(X_train, y_train)\n",
        "plt.plot(X_true, y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOuSrfWgrWLm"
      },
      "source": [
        "Now we have a simple dataset, we want to format it for linear regression. One easy assumption is that $y_i=\\theta x_i+\\epsilon$ where $\\epsilon\\sim\\mathcal N(0, \\sigma^2)$ is some measurement noise. We can the write this as $$y= X\\theta + \\epsilon ~~~\\text{ for }~ y=\\begin{bmatrix}y_1\\\\ \\vdots\\\\ y_n\\end{bmatrix}, X=\\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_n\\end{bmatrix}$$. The ML estimation of $\\theta$ will then be $\\theta=(X^TX)^{-1}X^Ty$ as covered in the lectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxPens2prVzb"
      },
      "outputs": [],
      "source": [
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "theta = np.matmul(np.linalg.inv(np.matmul(X.T, X)), np.matmul(X.T, y))\n",
        "\n",
        "y = np.matmul(X_true, theta)\n",
        "\n",
        "plt.scatter(X_train, y_train)\n",
        "plt.plot(X_true, y_true)\n",
        "plt.plot(X_true, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSQpjma9yDP5"
      },
      "source": [
        "Instead of just assuming that $y$ is proportional to $X$ we can assume linearity and add a constant term,\n",
        "$$y_i=\\theta_0 + \\theta_1 x_i=\\begin{bmatrix}1 & x_i\\end{bmatrix}\\begin{bmatrix}\\theta_0\\\\\\theta_1\\end{bmatrix}$$\n",
        "$$\\Rightarrow\\underbrace{\\begin{bmatrix}y_1\\\\\\vdots\\\\y_n\\end{bmatrix}}_Y = \\underbrace{\\begin{bmatrix}1 & x_1\\\\\\vdots\\\\1 & x_n\\end{bmatrix}}_X\\underbrace{\\begin{bmatrix}\\theta_0\\\\\\theta_1\\end{bmatrix}}_\\theta$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BruRm8Jty8I4"
      },
      "outputs": [],
      "source": [
        "def add_ones_column(X):\n",
        "    return np.hstack((np.ones(X.shape), X))\n",
        "\n",
        "X = add_ones_column(X_train)\n",
        "y = y_train\n",
        "\n",
        "theta = np.matmul(np.linalg.inv(np.matmul(X.T, X)), np.matmul(X.T, y))\n",
        "\n",
        "y = np.matmul(add_ones_column(X_true), theta)\n",
        "\n",
        "plt.scatter(X_train, y_train)\n",
        "plt.plot(X_true, y_true)\n",
        "plt.plot(X_true, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNvCeUmk1y5g"
      },
      "source": [
        "Let's also add the first $n$ monomials of $X$ as additional features.\n",
        "$$y_i=\\theta_0 + \\theta_1 x_i + \\dots + \\theta_n x_i^n=\\begin{bmatrix}1 & x_i & \\dots & x_i^n \\end{bmatrix}\\begin{bmatrix}\\theta_0\\\\\\theta_1\\\\\\vdots\\\\\\theta_n\\end{bmatrix}$$\n",
        "Run this for a few different degrees of polynomials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyFAhlht4LXW"
      },
      "outputs": [],
      "source": [
        "def create_monomials(X):\n",
        "    # Choose degree of polynomial here, for 1 we should get the same as above\n",
        "    n = 5\n",
        "    terms = []\n",
        "    for i in range(n + 1):\n",
        "        terms.append(X**i)\n",
        "    return np.hstack(terms)\n",
        "\n",
        "X = create_monomials(X_train)\n",
        "y = y_train\n",
        "\n",
        "theta = np.matmul(np.linalg.inv(np.matmul(X.T, X)), np.matmul(X.T, y))\n",
        "\n",
        "y = np.matmul(create_monomials(X_true), theta)\n",
        "\n",
        "plt.scatter(X_train, y_train)\n",
        "plt.plot(X_true, y_true)\n",
        "plt.plot(X_true, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByyTwVrOjG1t"
      },
      "source": [
        "## Scikit-Learn\n",
        "Scikit-Learn is a huge library of tools for machine learning. It contains methods for downloading well known datasets, methods for analysing and preprocessing data, for regression and classification and for creating training pipelines.\n",
        "\n",
        "For now we will just use it for loading a common dataset called the iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5GvGQKhmwty"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_obj = load_iris()\n",
        "\n",
        "print(\"size of data {}\\nnames of columns {}\\ntarget label size {}\\nlabel names {}\".format(iris_obj.data.shape, iris_obj.feature_names, iris_obj.target.shape, iris_obj.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "822qzx_KxE8R"
      },
      "source": [
        "## Pandas\n",
        "Now we want to use pandas dataframes to explore the data a bit. Lets create a dataframe for the data and the labels and then join them together so we have everything in one spot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAtDMRtcwJux"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(iris_obj.data, columns=iris_obj.feature_names)\n",
        "\n",
        "labels = pd.DataFrame(iris_obj.target, columns=pd.Index([\"species\"]))\n",
        "\n",
        "iris = data.join(labels)\n",
        "\n",
        "iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CrvFmp05O7p"
      },
      "source": [
        "Since we are just exploring for our sake and not doing learning, it would be nice to have the names of the species instead of the label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJY1ZUK8yCTE"
      },
      "outputs": [],
      "source": [
        "iris.species.replace({i:iris_obj.target_names[i] for i in range(len(iris_obj.target_names))}, inplace=True)\n",
        "iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QliTH4tw1d0N"
      },
      "source": [
        "Describe provides some useful information, all of the rows here (count, mean, std...) also have their own commands if you want them separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU73QBJIzX3o"
      },
      "outputs": [],
      "source": [
        "iris.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17_15J8s2Ksi"
      },
      "source": [
        "We can also apply these over groupings such as showing the information for each type of flower and gain some insight into what might be features that can be used for classifying them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3uhaQz7z8LJ"
      },
      "outputs": [],
      "source": [
        "iris.groupby(\"species\").describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRm_hEhj3J1R"
      },
      "source": [
        "We can also use `apply` to apply a function over each column to aggregate some custom statistic. For example if we wanted to find the difference between the minimum and maximum value for each feature we could create a function that finds that for a column and apply that over all columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvwLGu0n1QxM"
      },
      "outputs": [],
      "source": [
        "def feature_range(c):\n",
        "    return c.max() - c.min()\n",
        "\n",
        "iris.iloc[:, 0:4].apply(feature_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqcP05SA4Bo0"
      },
      "source": [
        "And we can also do this over the grouped data, but then we use `aggregate` instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_otkcdhM3_BK"
      },
      "outputs": [],
      "source": [
        "iris.groupby(\"species\").aggregate(feature_range)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "python_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
